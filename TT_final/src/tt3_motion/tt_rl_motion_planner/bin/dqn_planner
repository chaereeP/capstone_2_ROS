#!/usr/bin/env python
import argparse
import os.path as osp
import random, time
import numpy as np
import cv2
import rospy, rospkg

from tt_core_msgs.msg import MapFlag, XboxFlag
from cv_bridge import CvBridge, CvBridgeError

import tensorflow as tf
import tensorflow.contrib.layers as layers

from tt_dqn.dqn_utils import *

#import simulator

movingSpeed = 1.0
turningSpeed = 0.6
def tt_model_dqn(img_in, num_actions, scope, reuse=False):
    # as described in https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf
    with tf.variable_scope(scope, reuse=reuse):
        out = img_in
        with tf.variable_scope("convnet"):
            # original architecture
            out = layers.convolution2d(out, num_outputs=32, kernel_size=8, stride=4, activation_fn=tf.nn.relu)
            out = layers.convolution2d(out, num_outputs=64, kernel_size=4, stride=2, activation_fn=tf.nn.relu)
            out = layers.convolution2d(out, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu)
        out = layers.flatten(out)
        with tf.variable_scope("action_value"):
            out = layers.fully_connected(out, num_outputs=512,         activation_fn=tf.nn.relu)
            out = layers.fully_connected(out, num_outputs=num_actions, activation_fn=None)

        return out

def tt_model_dueling_dqn(img_in, num_actions, scope, reuse=False):
    # as described in https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf
    with tf.variable_scope(scope, reuse=reuse):
        out = img_in
        with tf.variable_scope("convnet"):
            # original architecture
            out = layers.convolution2d(out, num_outputs=32, kernel_size=8, stride=4, activation_fn=tf.nn.relu)
            out = layers.convolution2d(out, num_outputs=64, kernel_size=4, stride=2, activation_fn=tf.nn.relu)
            out = layers.convolution2d(out, num_outputs=64, kernel_size=3, stride=1, activation_fn=tf.nn.relu)
            out = layers.convolution2d(out, num_outputs=64, kernel_size=7, stride=1, activation_fn=tf.nn.relu)

        outA = layers.flatten(out)
        outV = layers.flatten(out)

        with tf.variable_scope("action_value"):
            outA = layers.fully_connected(outA, num_outputs=512,         activation_fn=tf.nn.relu)
            outA = layers.fully_connected(outA, num_outputs=num_actions, activation_fn=None)
            outV = layers.fully_connected(outV, num_outputs=512,         activation_fn=tf.nn.relu)
            outV = layers.fully_connected(outV, num_outputs=1, activation_fn=None)

        outQ = outV + tf.subtract(outA,tf.reduce_max(outA,axis=1,keep_dims=True))
        return outQ

simulator = {"width":31, "height":31, "center":15, "resol":3}
debug_scale_gray = 3

class dqn_planner:
    def __init__(self, session):
        replay_buffer_size=100
        frame_history_len=4
        self.img_h, self.img_w, self.img_c = simulator["height"]*debug_scale_gray, simulator["width"]*debug_scale_gray, 1
        input_shape = (self.img_h, self.img_w, frame_history_len * self.img_c)
        num_actions = 10

        self.bridge = CvBridge()
        self.session = session

        self.obs_t_ph              = tf.placeholder(tf.uint8, [None] + list(input_shape))
        self.act_t_ph              = tf.placeholder(tf.int32,   [None])
        self.rew_t_ph              = tf.placeholder(tf.float32, [None])
        self.obs_t_float           = tf.cast(self.obs_t_ph,   tf.float32) / 255.0

        self.current_q_func = tt_model_dueling_dqn(self.obs_t_float, num_actions, scope="q_func", reuse=False)
        self.replay_buffer = ReplayBuffer(replay_buffer_size, frame_history_len)

        ###########
        # RUN ENV #
        ###########

        self.saver = tf.train.Saver(tf.global_variables())
        rospack = rospkg.RosPack()
        root = rospack.get_path('tt_rl_motion_planner')
        model_path = root+'/src/tt_dqn/model/model/'
        self.ckpt = tf.train.get_checkpoint_state(model_path)
        if self.ckpt and tf.train.checkpoint_exists(self.ckpt.model_checkpoint_path):
            self.saver.restore(self.session, self.ckpt.model_checkpoint_path)
        else:
            print "no model found"

        self.num_episode = 0
        self.start_episode = 0

        self.dqn_sub = rospy.Subscriber("/map_gen/rl_map", MapFlag, self.callback, queue_size=1)
        self.action_pub = rospy.Publisher("/dqn_planner/ctrl", XboxFlag, queue_size=1)

        self.suction_on = 0

        return

    def callback(self, data):
        t0 = time.time()
        try:
            self.last_obs = self.bridge.imgmsg_to_cv2(data.frame, "mono8").reshape(self.img_h, self.img_w, -1)
        except CvBridgeError as e:
            print(e)

        xbox_msg = XboxFlag()
        xbox_msg.header.stamp = data.header.stamp
        xbox_msg.Float32MultiArray.data = [0]*24
        if data.flag == 3:
            xbox_msg.flag = 0
        else:
            xbox_msg.flag = data.flag
        #cv2.imshow("dqn test",self.last_obs)
        #cv2.waitKey(1)

        # 0: run dqn, 1: run astar, 2: run astar and send done, 3: run dqn with slow speed
        if data.flag == 0 or data.flag == 3:
            idx = self.replay_buffer.store_frame(self.last_obs)
            input_batch = self.replay_buffer.encode_recent_observation()
            q_vals = self.session.run(self.current_q_func, {self.obs_t_ph: input_batch[None, :]})
            act = np.argmax(q_vals)
            print act
            print q_vals
            self.replay_buffer.store_effect(idx, act, 0, False)
            self.start_episode = 1
            xbox_msg.Float32MultiArray.data = self.mapAction(act, data.flag)
            self.action_pub.publish(xbox_msg)
        elif data.flag == 1:
            self.suction_on = 10
            self.action_pub.publish(xbox_msg)
        elif data.flag == 2:
            if self.start_episode == 1:
                idx = self.replay_buffer.store_frame(self.last_obs)
                input_batch = self.replay_buffer.encode_recent_observation()
                q_vals = self.session.run(self.current_q_func, {self.obs_t_ph: input_batch[None, :]})
                act = np.argmax(q_vals)
                print act
                print q_vals
                self.replay_buffer.store_effect(idx, act, 0, True)
                self.num_episode = self.num_episode + 1
                self.start_episode = 0
            self.action_pub.publish(xbox_msg)
        else:
            self.action_pub.publish(xbox_msg)

        t1 = time.time()
        rospy.loginfo("dqn time %s", format(t1-t0))

        return

    def mapAction(self, action, flag):
        data = [0]*24

    	# data[0] = 0; //lx*data[3];
    	# data[1] = 0; //ly*data[3];
    	# data[2] = 0; //GamepadStickAngle(_dev, STICK_LEFT);
    	# data[3] = 0; //GamepadStickLength(_dev, STICK_LEFT);
    	# data[4] = 0; //rx*data[7];
    	# data[5] = 0; //ry*data[7];
    	# data[6] = 0; //GamepadStickAngle(_dev, STICK_RIGHT);
    	# data[7] = 0; //GamepadStickLength(_dev, STICK_RIGHT);
    	# data[8] = 0; //GamepadTriggerLength(_dev, TRIGGER_LEFT);
    	# data[9] = 0; //GamepadTriggerLength(_dev, TRIGGER_RIGHT);
    	# data[10] = 0; //GamepadButtonDown(_dev, BUTTON_DPAD_UP);
    	# data[11] = 0; //GamepadButtonDown(_dev, BUTTON_DPAD_DOWN);
    	# data[12] = 0; //GamepadButtonDown(_dev, BUTTON_DPAD_LEFT);
    	# data[13] = 0; //GamepadButtonDown(_dev, BUTTON_DPAD_RIGHT);
    	# data[14] = 0; //GamepadButtonDown(_dev, BUTTON_A); // duct on/off
    	# data[15] = 0; //GamepadButtonDown(_dev, BUTTON_B);
    	# data[16] = 0; //GamepadButtonDown(_dev, BUTTON_X);
    	# data[17] = 0; //GamepadButtonDown(_dev, BUTTON_Y);
    	# data[18] = 0; //GamepadButtonDown(_dev, BUTTON_BACK);
    	# data[19] = 0; //GamepadButtonDown(_dev, BUTTON_START);
    	# data[20] = 0; //GamepadButtonDown(_dev, BUTTON_LEFT_SHOULDER);
    	# data[21] = 0; //GamepadButtonDown(_dev, BUTTON_RIGHT_SHOULDER);
    	# data[22] = 0; //GamepadButtonDown(_dev, BUTTON_LEFT_THUMB);
    	# data[23] = 0; //GamepadButtonDown(_dev, BUTTON_RIGHT_THUMB);

        if self.suction_on > 0:
            data[14] = 1
            self.suction_on = self.suction_on - 1

        if flag == 0:
            movingSpeed = 1
        else:
            movingSpeed = 0.6

        if action == 0: # forward
            data[1] = movingSpeed
        elif action == 1: # forward right
            data[0] = movingSpeed/1.414
            data[1] = movingSpeed/1.414
        elif action == 2: # right
            data[0] = movingSpeed
        elif action == 3: # backward right
            data[0] = movingSpeed/1.414
            data[1] = -movingSpeed/1.414
        elif action == 4: # backward
            data[1] = -movingSpeed
        elif action == 5: # bacward left
            data[0] = -movingSpeed/1.414
            data[1] = -movingSpeed/1.414
        elif action == 6: # left
            data[0] = -movingSpeed
        elif action == 7: # forward left
            data[0] = -movingSpeed/1.414
            data[1] = movingSpeed/1.414
        elif action == 8: # turn left
            data[8] = turningSpeed
        elif action == 9: # turn right
            data[9] = turningSpeed
        else:
            data = [0]*24

        return data

def get_session():
    tf.reset_default_graph()
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)
    tf_config = tf.ConfigProto(
        inter_op_parallelism_threads=1,
        gpu_options=gpu_options)
    session = tf.Session(config=tf_config)
    print("AVAILABLE GPUS: ", get_available_gpus())
    return session

def get_available_gpus():
    from tensorflow.python.client import device_lib
    local_device_protos = device_lib.list_local_devices()
    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']

def main():
    session = get_session()
    rospy.init_node('tt_dqn_planner', anonymous=True)
    planner = dqn_planner(session)

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

if __name__ == "__main__":
    main()
